# bruno-memory

**Memory storage and retrieval system for the Bruno AI Platform**

bruno-memory provides production-ready memory backend implementations for the [bruno-core](https://github.com/meggy-ai/bruno-core) framework. Store and retrieve conversation history, manage user context, and perform semantic search across multiple storage backends through a unified interface.

---

## âœ¨ Features

### Core Capabilities
- ğŸ”Œ **Unified Interface**: All backends implement `MemoryInterface` from bruno-core
- âš¡ **Multiple Backends**: SQLite, PostgreSQL, Redis, ChromaDB, Qdrant
- ğŸ”„ **Async-First**: Built on asyncio for non-blocking I/O
- ğŸ­ **Factory Pattern**: Easy backend instantiation and configuration
- ğŸ§  **Smart Context**: Intelligent context window management with multiple strategies
- ğŸ” **Semantic Search**: Vector-based similarity search (ChromaDB, Qdrant)

### Advanced Features
- ğŸ’¾ **Multi-Level Caching**: In-memory and Redis caching for performance
- ğŸ“¦ **Conversation Management**: Session lifecycle, turn-taking, branching
- ğŸ—œï¸ **Memory Compression**: Automatic summarization using bruno-llm
- ğŸ¯ **Context Strategies**: Sliding window, semantic relevance, importance-based
- ğŸ“Š **Analytics**: Track memory usage, conversation patterns, costs
- ğŸ” **Privacy & Security**: Encryption at rest, data anonymization, GDPR compliance
- ğŸ”„ **Migration Support**: Schema versioning and data migration tools

---

## ğŸš€ Quick Start

### Installation

```bash
# Basic installation (SQLite only)
pip install bruno-memory

# With PostgreSQL support
pip install bruno-memory[postgresql]

# With Redis caching
pip install bruno-memory[redis]

# With vector databases
pip install bruno-memory[vector]

# With embeddings support
pip install bruno-memory[embeddings]

# All backends
pip install bruno-memory[all]
```

### Basic Usage

```python
from bruno_memory import MemoryFactory
from bruno_core.models import Message, MessageRole

# Create a SQLite backend (simplest, no setup)
memory = MemoryFactory.create("sqlite", {"database": "conversations.db"})

# Store a message
message = Message(role=MessageRole.USER, content="Hello, Bruno!")
await memory.store_message(message, conversation_id="conv_123")

# Retrieve conversation history
messages = await memory.retrieve_messages("conv_123", limit=10)

# Search across conversations
results = await memory.search_messages(
    query="timer",
    user_id="user_456",
    limit=5
)
```

### Using PostgreSQL (Production)

```python
memory = MemoryFactory.create("postgresql", {
    "host": "localhost",
    "port": 5432,
    "database": "bruno_memory",
    "user": "bruno",
    "password": "secure_password"
})
```

### Using Redis (Caching)

```python
# Fast in-memory caching with optional persistence
memory = MemoryFactory.create("redis", {
    "host": "localhost",
    "port": 6379,
    "db": 0,
    "ttl": 3600  # 1 hour expiration
})
```

### Semantic Search with Vector Databases

```python
from bruno_memory import MemoryFactory
from bruno_llm import LLMFactory

# Create embedding provider
llm = LLMFactory.create("openai", {"api_key": "sk-..."})

# Create vector backend
memory = MemoryFactory.create("chromadb", {
    "persist_directory": "./chroma_data",
    "embedding_provider": llm
})

# Store with automatic embedding
await memory.store_message(message, conversation_id="conv_123")

# Semantic search
similar = await memory.search_memories(
    user_id="user_123",
    query="Tell me about music preferences",
    limit=5
)
```

---

## ğŸ“¦ Supported Backends

### SQLite
**Best for:** Development, single-user applications, simple deployments

- âœ… No external dependencies
- âœ… File-based storage
- âœ… Full-text search
- âœ… Fast for small-to-medium datasets
- âŒ Limited concurrent writes

### PostgreSQL
**Best for:** Production, multi-user applications, scalable deployments

- âœ… Production-grade reliability
- âœ… Advanced querying (JSON, full-text)
- âœ… pgvector for similarity search
- âœ… Excellent concurrency support
- âœ… ACID compliance

### Redis
**Best for:** High-speed caching, session management, real-time applications

- âœ… In-memory performance
- âœ… TTL-based expiration
- âœ… Pub/sub for real-time updates
- âœ… Cluster support
- âŒ Limited by RAM

### ChromaDB
**Best for:** Semantic search, RAG applications, small-to-medium datasets

- âœ… Easy setup
- âœ… Built-in embeddings
- âœ… Metadata filtering
- âœ… Local or client-server

### Qdrant
**Best for:** Large-scale semantic search, production vector workloads

- âœ… High performance
- âœ… Hybrid search (vector + metadata)
- âœ… Distributed deployment
- âœ… Rich filtering

---

## ğŸ—ï¸ Architecture

```
bruno-memory/
â”œâ”€â”€ backends/          # Storage implementations
â”‚   â”œâ”€â”€ sqlite/       # Local file-based
â”‚   â”œâ”€â”€ postgresql/   # Production database
â”‚   â”œâ”€â”€ redis/        # In-memory cache
â”‚   â””â”€â”€ vector/       # ChromaDB, Qdrant
â”œâ”€â”€ managers/         # Memory management
â”‚   â”œâ”€â”€ conversation  # Session management
â”‚   â”œâ”€â”€ context       # Context building
â”‚   â”œâ”€â”€ retriever     # Memory search
â”‚   â”œâ”€â”€ compressor    # Summarization
â”‚   â””â”€â”€ embedding     # Vector management
â””â”€â”€ utils/            # Utilities
    â”œâ”€â”€ cache         # Multi-level caching
    â”œâ”€â”€ migration     # Schema migrations
    â”œâ”€â”€ backup        # Export/import
    â””â”€â”€ analytics     # Usage tracking
```

---

## ğŸ“š Documentation

- [Quick Start Guide](docs/guides/quick_start.md)
- [Backend Selection Guide](docs/guides/backends.md)
- [Context Management](docs/guides/context_management.md)
- [Semantic Search](docs/guides/semantic_search.md)
- [API Reference](docs/api/)

---

## ğŸ§ª Testing

```bash
# Install dev dependencies
pip install bruno-memory[dev]

# Run tests
pytest

# With coverage
pytest --cov=bruno_memory --cov-report=html

# Run specific test suite
pytest tests/unit/
pytest tests/integration/
pytest tests/benchmarks/
```

---

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Setup

```bash
# Clone repository
git clone https://github.com/meggy-ai/bruno-memory.git
cd bruno-memory

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode
pip install -e ".[dev,all]"

# Install pre-commit hooks
pre-commit install

# Run tests
pytest
```

---

## ğŸ“‹ Requirements

- Python 3.10+
- bruno-core >= 0.1.0
- Backend-specific dependencies (optional)

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ”— Related Projects

- **[bruno-core](https://github.com/meggy-ai/bruno-core)**: Core interfaces and base implementations
- **[bruno-llm](https://github.com/meggy-ai/bruno-llm)**: LLM provider implementations
- **[bruno-abilities](https://github.com/meggy-ai/bruno-abilities)**: Action execution system
- **[bruno-pa](https://github.com/meggy-ai/bruno-pa)**: Personal assistant application

---

## ğŸ“® Support

- ğŸ› [Report bugs](https://github.com/meggy-ai/bruno-memory/issues)
- ğŸ’¡ [Request features](https://github.com/meggy-ai/bruno-memory/issues)
- ğŸ’¬ [Discussions](https://github.com/meggy-ai/bruno-memory/discussions)

---

## ğŸ—ºï¸ Roadmap

### v0.1.0 (Current)
- âœ… SQLite backend
- âœ… PostgreSQL backend
- âœ… Redis backend
- âœ… Basic memory management
- âœ… Context building

### v0.2.0 (Planned)
- ğŸ”œ ChromaDB integration
- ğŸ”œ Qdrant integration
- ğŸ”œ Semantic search
- ğŸ”œ Memory compression

### v0.3.0 (Future)
- ğŸ”® Advanced analytics
- ğŸ”® Privacy features
- ğŸ”® Performance optimizations

---

**Made with â¤ï¸ by the Meggy AI team**
